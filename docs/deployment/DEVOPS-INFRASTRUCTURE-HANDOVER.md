# ğŸ“‹ DOCUMENT DE PASSATION DEVOPS & INFRASTRUCTURE

## Zero Tolerance - Production Grade Documentation

**Version**: 1.0.0  
**Date**: 8 Janvier 2026  
**Auteur**: DevOps Team  
**Classification**: Documentation Critique

---

## ğŸ“‘ TABLE DES MATIÃˆRES

1. [Vue d'Ensemble de l'Infrastructure](#1-vue-densemble-de-linfrastructure)
2. [Dossier Docker - Conteneurisation](#2-dossier-docker---conteneurisation)
3. [Dossier Kubernetes - Orchestration](#3-dossier-kubernetes---orchestration)
4. [Dossier Terraform - Infrastructure as Code](#4-dossier-terraform---infrastructure-as-code)
5. [Dossier Monitoring - ObservabilitÃ©](#5-dossier-monitoring---observabilitÃ©)
6. [Dossier .github - CI/CD & Automatisation](#6-dossier-github---cicd--automatisation)
7. [Best Practices ImplÃ©mentÃ©es](#7-best-practices-implÃ©mentÃ©es)
8. [Matrice de Valeur AjoutÃ©e](#8-matrice-de-valeur-ajoutÃ©e)
9. [ProcÃ©dures OpÃ©rationnelles](#9-procÃ©dures-opÃ©rationnelles)
10. [Checklist de Passation](#10-checklist-de-passation)

---

## 1. VUE D'ENSEMBLE DE L'INFRASTRUCTURE

### ğŸ—ï¸ Architecture des Dossiers

```
Check-in-app/
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker/              # Conteneurisation locale et CI
â”‚   â”‚   â”œâ”€â”€ backend.Dockerfile
â”‚   â”‚   â”œâ”€â”€ frontend.Dockerfile
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”‚
â”‚   â”œâ”€â”€ kubernetes/          # Orchestration Production
â”‚   â”‚   â”œâ”€â”€ base/            # Ressources communes (Kustomize)
â”‚   â”‚   â”œâ”€â”€ staging/         # Overlay staging
â”‚   â”‚   â””â”€â”€ production/      # Overlay production
â”‚   â”‚
â”‚   â”œâ”€â”€ terraform/           # Infrastructure as Code
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚
â”‚   â””â”€â”€ monitoring/          # Stack ObservabilitÃ©
â”‚       â”œâ”€â”€ prometheus/
â”‚       â”œâ”€â”€ alertmanager/
â”‚       â””â”€â”€ grafana/
â”‚
â””â”€â”€ .github/
    â”œâ”€â”€ workflows/           # GitHub Actions CI/CD
    â”œâ”€â”€ CODEOWNERS           # Ownership Rules
    â””â”€â”€ dependabot.yml       # Auto-update Dependencies
```

### ğŸ¯ Objectifs de l'Infrastructure

| Objectif | Implementation | Status |
|----------|---------------|--------|
| **High Availability** | 2+ replicas, PDB, anti-affinity | âœ… |
| **Auto-scaling** | HPA (CPU/Memory) | âœ… |
| **Zero Downtime Deploy** | Rolling updates, readiness probes | âœ… |
| **Security Hardening** | Network policies, non-root, RBAC | âœ… |
| **Observability** | Prometheus + Alertmanager + Grafana | âœ… |
| **Infrastructure as Code** | Terraform + Kustomize | âœ… |
| **CI/CD Automation** | GitHub Actions multi-stage | âœ… |

---

## 2. DOSSIER DOCKER - CONTENEURISATION

### ğŸ“ Localisation: `infrastructure/docker/`

### 2.1 Backend Dockerfile

**Fichier**: `backend.Dockerfile`

#### Architecture Multi-Stage (3 stages)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: deps                                              â”‚
â”‚  â”œâ”€â”€ node:20-alpine                                         â”‚
â”‚  â”œâ”€â”€ Installe les dÃ©pendances systÃ¨me (python3, make, g++) â”‚
â”‚  â””â”€â”€ npm ci (toutes dÃ©pendances)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 2: builder                                           â”‚
â”‚  â”œâ”€â”€ Copie node_modules de deps                            â”‚
â”‚  â”œâ”€â”€ npm run build                                         â”‚
â”‚  â””â”€â”€ npm prune --production (supprime devDeps)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 3: runner (IMAGE FINALE)                            â”‚
â”‚  â”œâ”€â”€ node:20-alpine (image minimale)                       â”‚
â”‚  â”œâ”€â”€ Utilisateur non-root (nestjs:nodejs)                  â”‚
â”‚  â”œâ”€â”€ dumb-init (gestion signaux)                           â”‚
â”‚  â”œâ”€â”€ HEALTHCHECK intÃ©grÃ©                                   â”‚
â”‚  â””â”€â”€ Labels OCI standards                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Best Practices ImplÃ©mentÃ©es

| Practice | Implementation | Valeur AjoutÃ©e |
|----------|---------------|----------------|
| **Multi-stage build** | 3 stages sÃ©parÃ©s | Image finale ~150MB vs ~1GB |
| **Non-root user** | `USER nestjs` (uid 1001) | SÃ©curitÃ©: principe du moindre privilÃ¨ge |
| **dumb-init** | `ENTRYPOINT ["dumb-init", "--"]` | Gestion correcte SIGTERM/SIGKILL |
| **HEALTHCHECK** | curl sur `/api/v1/health` | Auto-restart si unhealthy |
| **OCI Labels** | `org.opencontainers.image.*` | TraÃ§abilitÃ©, audit, documentation |
| **Read-only FS compatible** | Volumes pour `/tmp`, `/app/logs` | SÃ©curitÃ© renforcÃ©e en K8s |

#### Commandes Utiles

```bash
# Build avec mÃ©tadonnÃ©es
docker build \
  --build-arg BUILD_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ") \
  --build-arg VCS_REF=$(git rev-parse HEAD) \
  -t checkin-backend:latest \
  -f infrastructure/docker/backend.Dockerfile \
  backend/

# VÃ©rifier la taille de l'image
docker images checkin-backend:latest --format "{{.Size}}"

# Scanner les vulnÃ©rabilitÃ©s
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image checkin-backend:latest
```

---

### 2.2 Frontend Dockerfile

**Fichier**: `frontend.Dockerfile`

#### Architecture Multi-Stage (3 stages)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: deps                                              â”‚
â”‚  â”œâ”€â”€ node:20-alpine + libc6-compat                         â”‚
â”‚  â””â”€â”€ npm ci                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 2: builder                                           â”‚
â”‚  â”œâ”€â”€ Build-time env: NEXT_PUBLIC_API_URL                   â”‚
â”‚  â”œâ”€â”€ NEXT_TELEMETRY_DISABLED=1                             â”‚
â”‚  â””â”€â”€ npm run build â†’ output: standalone                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 3: runner (IMAGE FINALE)                            â”‚
â”‚  â”œâ”€â”€ Next.js standalone output                             â”‚
â”‚  â”œâ”€â”€ Utilisateur non-root (nextjs:nodejs)                  â”‚
â”‚  â””â”€â”€ server.js optimisÃ©                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Configuration Requise (next.config.ts)

```typescript
// IMPORTANT: Activer dans next.config.ts pour le standalone build
module.exports = {
  output: 'standalone',
}
```

---

### 2.3 Docker Compose

**Fichier**: `docker-compose.yml`

#### Services DÃ©finis

| Service | Image | Port | RÃ´le |
|---------|-------|------|------|
| `mongodb` | mongo:7.0 | 27017 | Base de donnÃ©es principale |
| `redis` | redis:7-alpine | 6379 | Cache + Pub/Sub + Queue |
| `backend` | Build local | 3001 | API NestJS |
| `frontend` | Build local | 3000 | Web App Next.js |
| `nginx` | nginx:alpine | 80/443 | Reverse proxy (profil: production) |
| `prometheus` | prom/prometheus:v2.47.0 | 9090 | MÃ©triques |
| `grafana` | grafana/grafana | 3002 | Dashboards |

#### FonctionnalitÃ©s ClÃ©s

```yaml
# Health checks sur tous les services
healthcheck:
  test: ["CMD", "mongosh", "--eval", "db.runCommand('ping').ok"]
  interval: 10s
  timeout: 5s
  retries: 5
  start_period: 30s

# DÃ©pendances avec conditions
depends_on:
  mongodb:
    condition: service_healthy  # Attend que MongoDB soit healthy
  redis:
    condition: service_healthy

# Profils pour environnements diffÃ©rents
profiles:
  - production  # nginx uniquement en production
```

#### Commandes Essentielles

```bash
# DÃ©veloppement local (sans nginx)
docker-compose up -d mongodb redis backend frontend

# Avec monitoring
docker-compose --profile monitoring up -d

# Production locale (avec nginx)
docker-compose --profile production up -d

# Voir les logs en temps rÃ©el
docker-compose logs -f backend

# Rebuild aprÃ¨s changement de code
docker-compose up -d --build backend
```

---

## 3. DOSSIER KUBERNETES - ORCHESTRATION

### ğŸ“ Localisation: `infrastructure/kubernetes/`

### 3.1 Structure Kustomize

```
kubernetes/
â”œâ”€â”€ base/                     # Ressources communes
â”‚   â”œâ”€â”€ kustomization.yaml    # Manifest principal
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â”œâ”€â”€ frontend-deployment.yaml
â”‚   â”œâ”€â”€ mongodb-statefulset.yaml
â”‚   â”œâ”€â”€ redis-deployment.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ secrets.yaml
â”‚   â”œâ”€â”€ services.yaml
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”œâ”€â”€ hpa.yaml              # Auto-scaling
â”‚   â”œâ”€â”€ pdb.yaml              # Pod Disruption Budget
â”‚   â””â”€â”€ network-policies.yaml # SÃ©curitÃ© rÃ©seau
â”‚
â”œâ”€â”€ staging/
â”‚   â””â”€â”€ kustomization.yaml    # Overlay staging
â”‚
â””â”€â”€ production/
    â””â”€â”€ kustomization.yaml    # Overlay production
```

### 3.2 Backend Deployment - Analyse DÃ©taillÃ©e

**Fichier**: `base/backend-deployment.yaml`

#### Configuration Haute DisponibilitÃ©

```yaml
spec:
  replicas: 2                    # Minimum 2 pods
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1                # +1 pod pendant update
      maxUnavailable: 0          # Jamais 0 pod disponible
```

#### SÃ©curitÃ© RenforcÃ©e

```yaml
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true       # Interdit root
        runAsUser: 1001          # UID spÃ©cifique
        fsGroup: 1001            # GID pour volumes
      
      containers:
        - securityContext:
            allowPrivilegeEscalation: false  # Bloque escalade
            readOnlyRootFilesystem: true     # FS lecture seule
            capabilities:
              drop:
                - ALL                         # Supprime capabilities
```

#### Probes de SantÃ©

| Probe | Endpoint | Comportement |
|-------|----------|--------------|
| **livenessProbe** | `/api/v1/health` | Restart si Ã©chec 3x |
| **readinessProbe** | `/api/v1/health` | Retire du service si unhealthy |

```yaml
livenessProbe:
  httpGet:
    path: /api/v1/health
    port: http
  initialDelaySeconds: 30      # DÃ©lai au dÃ©marrage
  periodSeconds: 10            # VÃ©rification toutes les 10s
  timeoutSeconds: 5
  failureThreshold: 3          # 3 Ã©checs â†’ restart

readinessProbe:
  httpGet:
    path: /api/v1/health
    port: http
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3
```

#### Ressources et Limites

```yaml
resources:
  requests:                    # Garantis
    cpu: "100m"               # 0.1 CPU
    memory: "256Mi"           # 256 MB RAM
  limits:                      # Maximum
    cpu: "500m"               # 0.5 CPU
    memory: "512Mi"           # 512 MB RAM
```

#### Anti-Affinity et Topology Spread

```yaml
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: backend
          topologyKey: kubernetes.io/hostname  # DiffÃ©rents nodes

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone   # DiffÃ©rentes zones
    whenUnsatisfiable: ScheduleAnyway
```

**RÃ©sultat**: Les pods backend sont distribuÃ©s sur diffÃ©rents nodes ET diffÃ©rentes zones de disponibilitÃ©.

---

### 3.3 Horizontal Pod Autoscaler (HPA)

**Fichier**: `base/hpa.yaml`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend
  minReplicas: 2               # Minimum 2 pods
  maxReplicas: 10              # Maximum 10 pods
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70   # Scale si CPU > 70%
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80   # Scale si RAM > 80%
```

#### Comportement de Scaling

```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: 300    # Attend 5min avant scale down
    policies:
      - type: Percent
        value: 10                       # Max -10% pods par minute
        periodSeconds: 60
  scaleUp:
    stabilizationWindowSeconds: 0      # Scale up immÃ©diat
    policies:
      - type: Percent
        value: 100                      # Double si nÃ©cessaire
        periodSeconds: 15
      - type: Pods
        value: 4                        # Ou +4 pods
        periodSeconds: 15
    selectPolicy: Max                   # Choix le plus agressif
```

---

### 3.4 Pod Disruption Budget (PDB)

**Fichier**: `base/pdb.yaml`

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: backend-pdb
spec:
  minAvailable: 1              # Toujours au moins 1 pod disponible
  selector:
    matchLabels:
      app: backend
```

**Valeur AjoutÃ©e**: Lors d'une maintenance cluster (drain node, mise Ã  jour), Kubernetes garantit qu'au moins 1 pod reste disponible.

---

### 3.5 Network Policies

**Fichier**: `base/network-policies.yaml`

#### RÃ¨gles de SÃ©curitÃ© RÃ©seau

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGRESS CONTROLLER                        â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Frontend  â”‚â”€â”€â”€â–ºâ”‚  Backend   â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                          â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚            â–¼             â–¼             â–¼                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚     â”‚ MongoDB  â”‚  â”‚  Redis   â”‚  â”‚ kube-dns â”‚               â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Source | Destination | Port | AutorisÃ© |
|--------|-------------|------|----------|
| Frontend | Backend | 3001 | âœ… |
| Ingress | Backend | 3001 | âœ… |
| Backend | MongoDB | 27017 | âœ… |
| Backend | Redis | 6379 | âœ… |
| Backend | kube-dns | 53/UDP | âœ… |
| MongoDB | Internet | * | âŒ |
| Redis | Internet | * | âŒ |

---

### 3.6 Ingress Configuration

**Fichier**: `base/ingress.yaml`

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: checkin-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    # Rate limiting
    nginx.ingress.kubernetes.io/limit-rps: "100"
    nginx.ingress.kubernetes.io/limit-connections: "50"
spec:
  tls:
    - hosts:
        - checkin-app.example.com
        - api.checkin-app.example.com
      secretName: checkin-tls
  rules:
    - host: checkin-app.example.com      # Frontend
    - host: api.checkin-app.example.com  # Backend
```

#### Commandes Kubernetes Essentielles

```bash
# DÃ©ployer avec Kustomize
kubectl apply -k infrastructure/kubernetes/staging/

# VÃ©rifier le dÃ©ploiement
kubectl get all -n checkin

# Voir les logs d'un pod
kubectl logs -f deployment/backend -n checkin

# Scale manuel temporaire
kubectl scale deployment/backend --replicas=4 -n checkin

# Rollback en cas de problÃ¨me
kubectl rollout undo deployment/backend -n checkin

# VÃ©rifier les network policies
kubectl get networkpolicies -n checkin
```

---

## 4. DOSSIER TERRAFORM - INFRASTRUCTURE AS CODE

### ğŸ“ Localisation: `infrastructure/terraform/`

### 4.1 Structure des Fichiers

| Fichier | RÃ´le |
|---------|------|
| `main.tf` | Ressources principales |
| `variables.tf` | Variables d'entrÃ©e |
| `outputs.tf` | Valeurs de sortie |
| `prometheus-values.yaml` | Configuration Helm Prometheus |

### 4.2 Ressources CrÃ©Ã©es

```hcl
# Namespace Kubernetes
resource "kubernetes_namespace" "checkin" { ... }

# Secrets (gÃ©nÃ©rÃ©s automatiquement)
resource "random_password" "mongodb_root_password" {
  length           = 24
  special          = true
}
resource "kubernetes_secret" "app_secrets" { ... }
resource "kubernetes_secret" "mongodb_secrets" { ... }

# ConfigMap
resource "kubernetes_config_map" "app_config" { ... }

# Helm Charts
resource "helm_release" "nginx_ingress" { ... }
resource "helm_release" "cert_manager" { ... }
resource "helm_release" "prometheus" { ... }  # Optionnel
```

### 4.3 Variables Configurables

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `namespace` | string | `checkin` | Namespace K8s |
| `environment` | string | `staging` | `staging` ou `production` |
| `log_level` | string | `info` | Niveau de log |
| `checkin_late_threshold` | number | `10` | Minutes avant check-in tardif |
| `install_monitoring` | bool | `false` | Installer Prometheus/Grafana |
| `install_cert_manager` | bool | `true` | Installer cert-manager |

### 4.4 Commandes Terraform

```bash
# Initialisation
cd infrastructure/terraform
terraform init

# PrÃ©visualisation
terraform plan -var="environment=staging"

# Application
terraform apply -var="environment=staging"

# Destruction (attention!)
terraform destroy -var="environment=staging"

# Import ressource existante
terraform import kubernetes_namespace.checkin checkin
```

---

## 5. DOSSIER MONITORING - OBSERVABILITÃ‰

### ğŸ“ Localisation: `infrastructure/monitoring/`

### 5.1 Stack d'ObservabilitÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ALERTMANAGER                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Routes: critical â†’ Slack/Email/PagerDuty           â”‚    â”‚
â”‚  â”‚          database â†’ DBA team                        â”‚    â”‚
â”‚  â”‚          security â†’ Security team                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â–²                                  â”‚
â”‚                           â”‚ Alertes                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    PROMETHEUS                        â”‚    â”‚
â”‚  â”‚  â€¢ Scrape: backend, frontend, mongodb, redis        â”‚    â”‚
â”‚  â”‚  â€¢ Rules: 50+ alertes prÃ©dÃ©finies                   â”‚    â”‚
â”‚  â”‚  â€¢ Retention: 15 jours                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                     GRAFANA                          â”‚    â”‚
â”‚  â”‚  â€¢ Dashboards: API Performance, DB Stats, Redis     â”‚    â”‚
â”‚  â”‚  â€¢ Alerting: Visual thresholds                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Prometheus Configuration

**Fichier**: `monitoring/prometheus/prometheus.yml`

#### Jobs de Scraping

| Job | Target | MÃ©triques |
|-----|--------|-----------|
| `prometheus` | localhost:9090 | Self-monitoring |
| `backend-api` | pods avec label `app: backend` | HTTP latency, request count, errors |
| `mongodb` | mongodb-exporter | Connections, operations, replication |
| `redis` | redis-exporter | Memory, commands, keys |

### 5.3 Alert Rules

**Fichier**: `monitoring/prometheus/alert_rules.yml`

#### CatÃ©gories d'Alertes

| Groupe | Alertes | SÃ©vÃ©ritÃ© |
|--------|---------|----------|
| **application-health** | BackendDown, FrontendDown, HighErrorRate | Critical/Warning |
| **latency-alerts** | HighAPILatency, CriticalAPILatency, SlowDBQueries | Warning/Critical |
| **database-alerts** | MongoDBDown, HighConnections, ReplicationLag | Critical/Warning |
| **redis-alerts** | RedisDown, HighMemory, ConnectionsExhausted | Critical/Warning |
| **kubernetes-alerts** | PodCrashLooping, HighRestartCount | Critical |
| **business-alerts** | HighCheckInFailures, CapacityReached | Warning |

#### Exemple d'Alerte

```yaml
- alert: BackendDown
  expr: up{job="backend-api"} == 0
  for: 1m
  labels:
    severity: critical
    component: backend
  annotations:
    summary: "Backend API is down"
    description: "Instance {{ $labels.instance }} down for 1+ minute"
    runbook_url: "https://docs.checkin-app.com/runbooks/backend-down"
```

### 5.4 Alertmanager Routing

**Fichier**: `monitoring/alertmanager/alertmanager.yml`

```yaml
route:
  receiver: 'default-receiver'
  group_by: ['alertname', 'severity', 'component']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s              # Notification rapide
      repeat_interval: 1h
      
    - match:
        component: security
      receiver: 'security-alerts'
      group_wait: 10s              # SÃ©curitÃ© = prioritÃ©
```

---

## 6. DOSSIER .GITHUB - CI/CD & AUTOMATISATION

### ğŸ“ Localisation: `.github/`

### 6.1 Vue d'Ensemble des Workflows

```
.github/
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ backend-ci.yml          # CI Backend (6 stages)
â”‚   â”œâ”€â”€ frontend-ci.yml         # CI Frontend (5 stages)
â”‚   â”œâ”€â”€ mobile-ci.yml           # CI Mobile Flutter
â”‚   â”œâ”€â”€ deploy-production.yml   # DÃ©ploiement multi-env
â”‚   â””â”€â”€ security-scan.yml       # Scans sÃ©curitÃ© hebdomadaires
â”œâ”€â”€ CODEOWNERS                   # Ownership automatique
â””â”€â”€ dependabot.yml               # Mise Ã  jour dÃ©pendances
```

### 6.2 Backend CI Pipeline

**Fichier**: `.github/workflows/backend-ci.yml`

#### Pipeline Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: LINT                                               â”‚
â”‚  â”œâ”€â”€ ESLint                                                 â”‚
â”‚  â”œâ”€â”€ Prettier check                                         â”‚
â”‚  â””â”€â”€ TypeScript compilation                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 2: UNIT TESTS  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”œâ”€â”€ Jest avec coverage                 â”‚                   â”‚
â”‚  â”œâ”€â”€ Upload Codecov                     â”‚ ParallÃ¨le         â”‚
â”‚  â””â”€â”€ Threshold check (>30%)             â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 3: E2E TESTS   â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”œâ”€â”€ Services: MongoDB 7.0, Redis 7    â”‚                   â”‚
â”‚  â””â”€â”€ npm run test:e2e                   â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 4: SECURITY SCAN  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚  â”œâ”€â”€ npm audit                                              â”‚
â”‚  â”œâ”€â”€ Snyk scan                                              â”‚
â”‚  â””â”€â”€ CodeQL analysis                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 5: BUILD DOCKER (main/develop only)                  â”‚
â”‚  â”œâ”€â”€ Multi-arch build (amd64)                               â”‚
â”‚  â”œâ”€â”€ Push to GHCR                                           â”‚
â”‚  â”œâ”€â”€ Generate SBOM                                          â”‚
â”‚  â””â”€â”€ Cache layers (type=gha)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stage 6: SCAN CONTAINER                                    â”‚
â”‚  â””â”€â”€ Trivy vulnerability scan â†’ SARIF                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### DÃ©clencheurs

```yaml
on:
  push:
    branches: [main, develop, 'feature/**', 'release/**']
    paths:
      - 'backend/**'
      - '.github/workflows/backend-ci.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'backend/**'
```

#### Concurrency Control

```yaml
concurrency:
  group: backend-${{ github.ref }}
  cancel-in-progress: true        # Annule les jobs prÃ©cÃ©dents sur mÃªme branche
```

### 6.3 Deploy Production Pipeline

**Fichier**: `.github/workflows/deploy-production.yml`

#### Workflow Manuel avec Inputs

```yaml
on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        type: choice
        options:
          - staging
          - production
      backend_version:
        description: 'Backend image tag'
        required: false
      skip_tests:
        description: 'Skip pre-deployment tests (NOT recommended)'
        type: boolean
        default: false
```

#### Stages de DÃ©ploiement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. VALIDATE                                                 â”‚
â”‚  â”œâ”€â”€ VÃ©rifie branche (production = main only)               â”‚
â”‚  â””â”€â”€ VÃ©rifie existence des images Docker                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. SMOKE TESTS (si skip_tests = false)                     â”‚
â”‚  â”œâ”€â”€ DÃ©marre backend avec MongoDB/Redis                     â”‚
â”‚  â””â”€â”€ Tests: /health, /sessions, /participants               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. DEPLOY STAGING (si environment = staging)               â”‚
â”‚  â”œâ”€â”€ kubectl apply -k staging/                              â”‚
â”‚  â””â”€â”€ kubectl rollout status                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. DEPLOY PRODUCTION (si environment = production)         â”‚
â”‚  â”œâ”€â”€ Approval required (GitHub Environment)                 â”‚
â”‚  â”œâ”€â”€ kubectl apply -k production/                           â”‚
â”‚  â””â”€â”€ Post-deploy verification                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.4 Security Scan Pipeline

**Fichier**: `.github/workflows/security-scan.yml`

#### ExÃ©cution

- **Automatique**: Chaque lundi Ã  3h00 UTC
- **Manuel**: Via workflow_dispatch

#### Scans EffectuÃ©s

| Type | Outil | Cible |
|------|-------|-------|
| Dependencies (Node) | npm audit + Snyk | backend/, frontend/ |
| Dependencies (Flutter) | flutter pub audit | checkin_mobile/ |
| Code Analysis | CodeQL | JavaScript/TypeScript |
| Container Scanning | Trivy | Images Docker |
| Secret Detection | Gitleaks | Tout le repo |
| License Compliance | License Checker | DÃ©pendances |

### 6.5 CODEOWNERS

**Fichier**: `.github/CODEOWNERS`

```plaintext
# Default owner
* @medma

# Backend
/backend/ @medma
/backend/src/modules/checkins/ @medma

# Infrastructure (critique)
/infrastructure/ @medma
/.github/workflows/ @medma

# Configuration files
*.yml @medma
*.yaml @medma
Dockerfile @medma
*.tf @medma
```

**Effet**: Toute PR touchant ces fichiers requiert automatiquement l'approbation des owners listÃ©s.

### 6.6 Dependabot

**Fichier**: `.github/dependabot.yml`

#### Configuration

```yaml
updates:
  # Backend - Weekly
  - package-ecosystem: "npm"
    directory: "/backend"
    schedule:
      interval: "weekly"
      day: "monday"
    groups:
      nestjs:
        patterns: ["@nestjs/*"]
      mongodb:
        patterns: ["mongoose", "@nestjs/mongoose"]
      redis:
        patterns: ["ioredis", "@nestjs/bull", "bull", "cache-manager*"]
```

**Valeur AjoutÃ©e**: 
- PRs automatiques pour les mises Ã  jour de sÃ©curitÃ©
- Groupement intelligent (toutes les deps NestJS ensemble)
- Labels automatiques pour le triage

---

## 7. BEST PRACTICES IMPLÃ‰MENTÃ‰ES

### 7.1 SÃ©curitÃ©

| Practice | ImplÃ©mentation | Fichier |
|----------|---------------|---------|
| **Non-root containers** | `runAsUser: 1001` | Dockerfiles, Deployments |
| **Read-only filesystem** | `readOnlyRootFilesystem: true` | backend-deployment.yaml |
| **Network isolation** | NetworkPolicies strictes | network-policies.yaml |
| **Secrets management** | K8s Secrets + Terraform random | secrets.yaml, main.tf |
| **Vulnerability scanning** | Trivy, Snyk, CodeQL | backend-ci.yml, security-scan.yml |
| **RBAC** | ServiceAccount dÃ©diÃ© | backend-deployment.yaml |

### 7.2 Haute DisponibilitÃ©

| Practice | ImplÃ©mentation | Impact |
|----------|---------------|--------|
| **Multi-replica** | `replicas: 2` minimum | Pas de SPOF |
| **PodDisruptionBudget** | `minAvailable: 1` | Maintenance sans downtime |
| **Anti-affinity** | Spread sur nodes/zones | RÃ©sistance aux pannes |
| **Health probes** | liveness + readiness | Auto-recovery |
| **Rolling updates** | `maxUnavailable: 0` | Zero downtime deploy |

### 7.3 Performance

| Practice | ImplÃ©mentation | BÃ©nÃ©fice |
|----------|---------------|----------|
| **HPA** | CPU 70%, Memory 80% | Auto-scaling |
| **Resource limits** | requests + limits | QoS garanti |
| **Multi-stage Docker** | 3 stages | Images ~150MB |
| **Layer caching** | `cache-from: type=gha` | Builds rapides |

### 7.4 ObservabilitÃ©

| Practice | ImplÃ©mentation | Utilisation |
|----------|---------------|-------------|
| **Prometheus scraping** | `/api/v1/metrics` | MÃ©triques custom |
| **Structured logging** | Pino JSON | ELK/Loki compatible |
| **Alert rules** | 50+ rules | DÃ©tection proactive |
| **Runbook URLs** | Dans annotations | RÃ©ponse rapide |

---

## 8. MATRICE DE VALEUR AJOUTÃ‰E

### Par Composant

| Composant | Sans | Avec | Valeur AjoutÃ©e |
|-----------|------|------|----------------|
| **Docker Multi-stage** | ~1GB image | ~150MB | -85% taille |
| **HPA** | Scaling manuel | Auto 2-10 pods | Ã‰lasticitÃ© |
| **Network Policies** | Tout ouvert | Zero-trust | SÃ©curitÃ© |
| **CI Pipeline** | 0 validation | 6 stages | QualitÃ© garantie |
| **Alerting** | DÃ©couverte manuelle | 50+ alertes | ProactivitÃ© |
| **Dependabot** | Updates manuels | Auto-PRs | SÃ©curitÃ© continue |

### ROI EstimÃ©

| Investissement | Ã‰conomie | PÃ©riode |
|----------------|----------|---------|
| CI/CD setup (8h) | 2h/deploy Ã— 50 deploys/an = 100h | 1 an |
| Monitoring setup (4h) | 10h debug/incident Ã— 5 incidents = 50h | 1 an |
| IaC Terraform (6h) | 4h/env Ã— 3 envs = 12h saved per recreation | RÃ©current |

---

## 9. PROCÃ‰DURES OPÃ‰RATIONNELLES

### 9.1 DÃ©ploiement Standard

```bash
# 1. VÃ©rifier le status actuel
kubectl get pods -n checkin
kubectl get hpa -n checkin

# 2. DÃ©clencher le dÃ©ploiement via GitHub Actions
# â†’ Actions â†’ Deploy Production â†’ Run workflow
# â†’ Choisir: staging ou production
# â†’ Backend version: latest ou tag spÃ©cifique

# 3. Surveiller le rollout
kubectl rollout status deployment/backend -n checkin --timeout=300s

# 4. VÃ©rifier les mÃ©triques post-deploy
curl https://api.checkin-app.example.com/api/v1/health
```

### 9.2 Rollback d'Urgence

```bash
# MÃ©thode 1: Kubernetes rollback
kubectl rollout undo deployment/backend -n checkin

# MÃ©thode 2: Re-dÃ©ployer version prÃ©cÃ©dente via CI
# â†’ Actions â†’ Deploy Production
# â†’ Backend version: sha-abc123 (tag prÃ©cÃ©dent)

# VÃ©rification
kubectl rollout history deployment/backend -n checkin
```

### 9.3 Scaling Manuel

```bash
# Temporaire (sera Ã©crasÃ© par HPA)
kubectl scale deployment/backend --replicas=6 -n checkin

# Permanent (modifier HPA)
kubectl patch hpa backend-hpa -n checkin -p '{"spec":{"minReplicas":4}}'
```

### 9.4 Debug

```bash
# Logs en temps rÃ©el
kubectl logs -f deployment/backend -n checkin --all-containers

# Shell dans un pod
kubectl exec -it deployment/backend -n checkin -- /bin/sh

# Events rÃ©cents
kubectl get events -n checkin --sort-by='.lastTimestamp'

# Describe pod en erreur
kubectl describe pod <pod-name> -n checkin
```

---

## 10. CHECKLIST DE PASSATION

### âœ… Avant Passation

- [ ] AccÃ¨s GitHub repository (admin)
- [ ] AccÃ¨s Kubernetes cluster (kubectl configurÃ©)
- [ ] AccÃ¨s Container Registry (GHCR)
- [ ] Secrets documentÃ©s et stockÃ©s sÃ©curisÃ©
- [ ] Runbooks Ã  jour

### âœ… Configuration VÃ©rifiÃ©e

- [ ] `.env` files documentÃ©s (jamais commitÃ©s)
- [ ] Secrets Kubernetes crÃ©Ã©s
- [ ] ConfigMaps correctement configurÃ©s
- [ ] Ingress DNS configurÃ©
- [ ] Certificats TLS valides

### âœ… Monitoring OpÃ©rationnel

- [ ] Prometheus scraping fonctionnel
- [ ] Alertmanager configurÃ© (Slack/Email)
- [ ] Grafana dashboards importÃ©s
- [ ] Runbook URLs dans les alertes

### âœ… CI/CD Fonctionnel

- [ ] GitHub Actions secrets configurÃ©s
- [ ] CODEOWNERS actif
- [ ] Dependabot actif
- [ ] Branch protection rules

### âœ… Documentation

- [ ] Ce document lu et compris
- [ ] README de chaque composant
- [ ] Runbooks d'incident
- [ ] Contacts d'escalade

---

## ğŸ“ CONTACTS & ESCALADE

| Niveau | Responsable | Contact |
|--------|-------------|---------|
| L1 - Operations | DevOps On-Call | devops@checkin-app.com |
| L2 - Engineering | Backend Lead | backend-lead@checkin-app.com |
| L3 - Architecture | Tech Lead | tech-lead@checkin-app.com |

---

**Document gÃ©nÃ©rÃ© automatiquement - Version 1.0.0**  
**DerniÃ¨re mise Ã  jour**: 8 Janvier 2026
